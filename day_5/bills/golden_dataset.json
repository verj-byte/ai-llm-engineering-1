{"user_input": "Whaat is the importance of AI in the context of the Philippines' digital transformation and regulation?", "reference_contexts": ["TWENTIETH CONGRESS OF THE \nREPUBLIC OF THE PHILIPPINES \nFirst Regular Session\n25 ,JUL-2 P4 55\nSENATE\nS. No.\n25\nIntroduced by Senator PIA S. CAYETANO\nAN ACT\nREGULATING THE DEVELOPMENT AND USE OF ARTIFICIAL INTELLIGENCE \nSYSTEMS IN THE PHILIPPINES, PROMOTING ETHICAL AND RESPONSIBLE \nARTIFICIAL INTELLIGENCE INNOVATION, AND INTEGRATING \nSUSTAINABILITY AND FUTURES THINKING IN NATIONAL POLICY MAKING, \nAND FOR OTHER PURPOSES\nEXPLANATORY NOTE\nThe rise of Artificial Intelligence (AI) is profoundly transforming industries, \ngovernance systems, and societies worldwide. As the Phiiippines continues its digital \ntransformation journey, there is an urgent need for a nationai framework that ensures \nthe safe, responsibie, and ethical use of AI, aligned with our vision of an inclusive, \ninnovative, and secure digital future.\nThe European Union's landmark AI Act of 2024, the world's first comprehensive \nlegal framework on AI, highlights the importance of risk-based classification, \ntransparency, accountability, and human oversight.1 In the same way, the United Nations \nSecretary-General's High-Level Advisory Body on AI emphasizes the need for coordinated \nglobal governance to uphold rights-based, transparent, and inclusive AI development.2 \nThese international efforts reflect a growing giobal recognition. While AI holds vast \neconomic and societai potential, it must be accompanied by a robust regulatory legal \nframework.\n1 European Union AI Act. (2024). World's First Comprehensive AI Law \nhttps://digital-strategy.ec.europa.eu/en/policies/european-approach-artificial-intelligence \n2CD0 Magazine. (2024). UN advisory body's 7 key recommendations for global AI governance. \nhttps://www.cdomagazine.tech/aiml/un-advisory-bodys-7-key-recommendations-for-global-ai- \ngovernance?utm"], "reference": "The rise of Artificial Intelligence (AI) is profoundly transforming industries, governance systems, and societies worldwide. As the Philippines continues its digital transformation journey, there is an urgent need for a national framework that ensures the safe, responsible, and ethical use of AI, aligned with a vision of an inclusive, innovative, and secure digital future.", "synthesizer_name": "single_hop_specifc_query_synthesizer"}
{"user_input": "Wha is ASI?", "reference_contexts": ["AI presents enormous opportunities for the Philippines: improving public services, \nadvancing disaster resilience, modernizing agriculture, and enhancing education and \nhealthcare systems, among others. However, these innovations carry risks. AI systems \nrely on data and models that may be incomplete, biased, or manipulated, reflecting the \nsubjective or commercial choices of developers. These raise concerns such as algorithmic \nbias, discrimination, and AI hallucinations, where systems generate false or misleading \noutputs with confidence. Moreover, the global scientific and policy communities have \nraised alarms regarding the possible rise of Artificial Superintelligence (ASI), hypothetical \nAI systems surpassing human intelligence and potentially beyond human control.3 This \nrisk includes fears that such systems, if improperly secured or regulated, might gain \nunauthorized access to critical infrastructure, including military assets such as nuclear \nweapons, posing existential threats to humanity.\nIn view of these challenges, this bill seeks to strike a careful balance between \nencouraging technological innovation and ensuring that AI systems remain safe, ethical, \ntransparent, and under meaningful human oversight. Given that AI is still in its early \nstages, this bill provides a general framework to encourage its development in a \nresponsible and lawful manner. It envisions a future where AI supports Filipino ingenuity, \naddresses national development challenges, and protects the rights and welfare of every \ncitizen. The State bears the responsibility to ensure that AI will never be used to \nperpetrate crimes, abuse rights, cause harm or unintended consequences, whether \nthrough intent or accident, while supporting Filipino ingenuity and technological progress.\nIn view of the foregoing, the approval of this bill is earnestly sought.\nPIA S: CAY^ANO \\\n3 Center for Security and Emerging Technology. (2024). Securing Critical Infrastructure in the Age of AI. \nGeorgetown University https://cset.georgetown.edu/publication/securing-critical-infrastructure-in-the- \nage-of-ai/"], "reference": "ASI refers to Artificial Superintelligence, a hypothetical AI system surpassing human intelligence and potentially beyond human control, raising concerns about security and safety.", "synthesizer_name": "single_hop_specifc_query_synthesizer"}
{"user_input": "What is the significance of SectioN 10 in the AI Regulation Act?", "reference_contexts": ["TWENTIETH CONGRESS OF THE \nREPUBLIC OF THE PHILIPPINES \nFirst Regular Session\n)\nSENATE \nS. No. 2.ci\n25 JUL-2 P4:56\nn;-' :\nIntroduced by Senator PIA S. CAYETANO\nAN ACT\nREGULATING THE DEVELOPMENT AND USE OF ARTIFICIAL INTELLIGENCE \nSYSTEMS IN THE PHILIPPINES, PROMOTING ETHICAL AND RESPONSIBLE \nARTIFICIAL INTELLIGENCE INNOVATION, AND INTEGRATING \nSUSTAINABILITY AND FUTURES THINKING IN NATIONAL POLICY MAKING, \nAND FOR OTHER PURPOSES\nBe it enacted by the Senate and House of Representatives of the Philippines in \nCongress assembled:\n1 \nSection 1. Short Title. - This Act shall be known as the 'Artificial Intelligence\n2 \nRegulation Act (AIRA).\"\n3 \nSec. 2. Declaration of Policy. - It is the policy of the State to recognize that\n4 \nscience and technology are essential for national development and progress. The State\n5 \nshall give priority to research and development, invention, innovation, and their\n6 \nutilization; and to science and technology education, training, and services.1 In this\n7 \nregard, the State shall promote the responsible development and use of Artificial\n8 \nIntelligence (AI) to advance inclusive growth, public service delivery, innovation, and\n9 \nlong-term national resilience. It shall likewise institutionalize futures thinking and\n10 \nsustainability as core principles in education, governance, and innovation. Towards\n11 \nthis end, the State shall advance AI in a manner that is ethical, inclusive, transparent,\n12 \nand accountable.\n13 \nSec. 3. Objectives. - The objectives of this Act are the following:\n1 Article XIV, Section 10 of the Philippine Constitution"], "reference": "The provided context does not specify the content or significance of Section 10 in the AI Regulation Act.", "synthesizer_name": "single_hop_specifc_query_synthesizer"}
{"user_input": "What is the correct spelling of ASI in the context of AI regulation?", "reference_contexts": ["1 \na) Promote innovation, technological advancement, and the responsible\n2 \nand ethical use of AI in a manner that upholds the privacy, rights, safety,\n3 \nand dignity of all Filipinos;\n4 \nb) Recognize that AI enhances human productivity, creativity, and\n5 \nefficiency across all sectors, and may be harnessed as a tool to\n6 \ncomplement human work, \nimprove public service delivery, boost\n7 \neconomic competitiveness, and advance scientific, educational, and\n8 \ntechnological development;\n9 \nc) Ensure that AI systems should enhance human cognition and never\n10 \ndegrade it;\n11 \nd) Strike a balance between promoting technological advancements on AI\n12 \nand ensuring AI safety for purposes of public interest;\n13 \ne) Protect Filipino workers from undue displacement due to AI and to\n14 \nuphold their right to decent and sustainable work;\n15 \nf) Ensure that AI systems contribute to inclusive national development that\n16 \nprotects national security and respects human autonomy;\n17 \ng) Adapt to the rapid and evolving nature of AI technologies and\n18 \ncontinuously build institutional and regulatory capacities; and\n19 \nh) Ensure that policies of both the national and local governments on AI\n20 \nare driven by futures thinking, strategic foresight, and proactive risk\n21 \nmanagement, and are governed by \nprinciples \nof transparency,\n22 \naccountability, and sustainability.\n23 \nSec. 4. Coverage. - This Act shall regulate the development and use of all types\n24 \nof AI, including Artificial General Intelligence (AGI) and Artificial Superintelligence\n25 \n(ASI), as well as regulate AI foundation models, such as machine learning systems,\n26 \ngenerative AI, neural networks, expert systems, language learned models (LLMs), and\n27 \nGenerative Pre-trained Transformers. This shall apply to all individuals, corporations,\n28 \ninstitutions, and government agencies that develop, deploy, use or operate AI systems\n29 \nin the Philippines.\n30 \nSec. 5. Definition of Terms. - For the purposes of this Act:\n31 \na) Artificiai Inteiiigence (AI) - refers to systems that allow machines to\n32 \nthink like humans, such that they can display intelligent behavior by"], "reference": "The context refers to AI systems including Artificial General Intelligence (AGI) and Artificial Superintelligence (ASI), as well as AI foundation models. The term is spelled ASI, which stands for Artificial Superintelligence.", "synthesizer_name": "single_hop_specifc_query_synthesizer"}
{"user_input": "What AGI mean in AI policy?", "reference_contexts": ["1\n2\n3\n4\n5\n6\n7\n8 \n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20 \n21 \n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\nanalyzing the data and taking actions with some degree of autonomy to \nachieve specific goals.\nb) Artificial General Intelligence (AGI) - refers to AI systems with the \ncapacity to understand, learn, and apply knowledge across a broad \nrange of tasks at a level equal to or surpassing human intelligence.\nc) Artificial Superintelligence (ASI) - refers to hypothetical AI systems that \nsurpass human intelligence in all respects, including creativity, decision­\nmaking, and social intelligence.\nd) AI Foundation Model- refers to a type of large-scale artificial intelligence \nmodel trained on vast quantities of broad data using self-supervised \nlearning or similar techniques, and which can be adapted to a wide range \nof downstream tasks, such as question answering, summarization, \ntranslation, classification, or content generation, with minimal task- \nspecific tuning. Foundation models include, but are not limited to, LLMs, \nmultimodal models, and generative models.\ne) Deployment in AI - refers to the process of integrating and operating a \ntrained AI model into an organizational infrastructure or real-world \nenvironment where it can perform its intended tasks.\nf) Expert Systems - refer to computer programs designed to simulate the \ndecision-making abilities of a human expert in a specific domain.\ng) Futures Thinking - refers to an avenue to strategically explore a range \nof \"possible futures\", with the aim of uncovering unexpected \nopportunities and mitigate potential risks.\nh) Generative Pre-trained Transformers- refer to a type of large language \nmodel based on the transformer architecture that generate human-like \ntext by predicting the next word in a sequence.\ni) Hallucination in AI- refers to the phenomenon wherein an AI system \ngenerates output that is syntactically correct or plausible-sounding but \nfactually incorrect, fabricated, or nonsensical. Hallucinations can occur \nin text, image, audio, or multimodal outputs, and are often the result of \nthe model extrapolating beyond the data it was trained on or failing to"], "reference": "Artificial General Intelligence (AGI) refers to AI systems with the capacity to understand, learn, and apply knowledge across a broad range of tasks at a level equal to or surpassing human intelligence.", "synthesizer_name": "single_hop_specifc_query_synthesizer"}
{"user_input": "What is the role of the National AI Commission as established in Sec. 5?", "reference_contexts": ["1 \nground its responses in verifiable information. There are two (2) general\n2 \ntypes:\n3 \ni) Intrinsic hallucination - when the model generates content\n4 \ninconsistent with the source input or prompt.\n5 \nii) \nExtrinsic hallucination - when the content is not supported by the\n6 \ninput but cannot be definitively labeled as incorrect due to lack of\n7 \nground truth.\n8 \nj) Highest level of responsibility and ethical consideration - refers to the\n9 \nlevel of diligence required of all persons, corporations, institutions, and\n10 \norganizations engaged in the development and deployment of AI to\n11 \nensure that AI systems are developed and used for the common good\n12 \nand does not facilitate crime, harm, or social injustice.\n13 \nk) Machine Learning (ML) - refers to a subset of AI that enables systems\n14 \nto learn from data and improve performance over time without being\n15 \nexplicitly programmed.\n16 \nI) Neural Networks - refer to computational models inspired by the\n17 \nstructure and function of the human brain, designed to recognize\n18 \npatterns and relationships in data.\n19 \nm) Generative AI- refers to AI systems capable of producing text, images,\n20 \nmusic, video, or other content including LLM.\n21 \nn) Large Language Models (LLMs)-refer to a type of generative AI trained\n22 \non vast datasets to generate human-like text, translate language,\n23 \nsummarize information, or answer questions.\n24 \no) Multimodal Models- refer to systems designed to process and integrate\n25 \ninformation from multiple data modalities—such as text, images, audio,\n26 \nand video—within a single unified framework. These models learn to\n27 \nunderstand and generate responses by finding relationships and\n28 \npatterns across different types of inputs.\n29 \nSec. 5. National AI Commission. - There is hereby established a policy-making\n30 \nand quasi-judicial body to be known as the National AI Commission, hereinafter\n31 \nreferred to as \"NAIC.\" The NAIC shall be an agency attached to the Department of\n32 \nScience and Technology (DOST)."], "reference": "The National AI Commission, referred to as \"NAIC,\" is a policy-making and quasi-judicial body established to oversee AI-related regulations and standards. It is an agency attached to the Department of Science and Technology (DOST).", "synthesizer_name": "single_hop_specifc_query_synthesizer"}
{"user_input": "What is the role of CHED within the NAIC?", "reference_contexts": ["1 \nSec. 6. Jurisdiction of the NAIC - The NAIC shall have the original and exclusive\n2 \njurisdiction over all matters pertaining to AI, including its development, promotion,\n3 \nregistration and regulation. The NAIC shall have quasi-judicial powers to hear and\n4 \ndecide on cases, and impose administrative sanctions provided under Sec. 20 of this\n5 \nAct.\n6 \nThe NAIC shall be responsible for technical support and policy alignment of all\n7 \ngovernment offices, including those under or attached to the DOST and other\n8 \nconcerned agencies involved in AI development. The NAIC shall also have the\n9 \nauthority to impose administrative penalties in case of any violation of this Act.\n10 \nSec. 7. Composition of the NAIC - The NAIC shall be composed of the\n11 \nSecretary of the DOST as Chairman, the Secretary of the Department of Information\n12 \nand Communications Technology (DICT) as Vice Chairperson, and the following as\n13 \nmembers:\n14 \na) Department of Trade and Industry (DTI);\n15 \nb) Department of Education (DepEd);\n16 \nc) Commission on Higher Education (CHED);\n17 \nd) Department of Labor and Employment (DOLE);\n18 \ne) Technical Education and Skills Development Authority (TESDA);\n19 \nf) Department of Justice (DOJ);\n20 \ng) National Privacy Commission (NPC);\n21 \nh) Department of Economy, Planning, and Development (DepDev);\n22 \ni) National Academy of Science and Technology (NAST); and\n23 \nj) One (1) representative each from the following sectors, to be appointed\n24 \nby the President of the Philippines for a term of three (3) years:\n25 \ni) \nThe private technology sector with expertise in AI or data science;\n26 \nii) \nThe civil society sector, with expertise in AI ethics, human rights,\n27 \nor digital governance.\n28 \nEach government agency member may designate a permanent representative\n29 \nto the NAIC, with a rank not lower than an Assistant Secretary or its equivalent, and\n30 \npreferably with proven expertise or relevant background in science and technology,\n31 \ninformation and communications technology, data governance, policy development,\n32 \nor legal and regulatory affairs."], "reference": "The Commission on Higher Education (CHED) is a member of the NAIC, which has jurisdiction over all matters pertaining to AI, including its development, promotion, registration, and regulation. CHED, as part of the NAIC's composition, contributes to the policy alignment and oversight of AI development in higher education sectors.", "synthesizer_name": "single_hop_specifc_query_synthesizer"}
{"user_input": "What role does the Intellectual Property Office play in the AI policies outlined by the NAIC?", "reference_contexts": ["1 \nSec. 8. NAICSecretariat. - The Secretariat shall implement and execute policies\n2 \non AI pursuant to the provisions of this Act. It shall be headed by an Executive\n3 \nDirector, with the rank of an Undersecretary.\n4 \nSubject to the review and approval of the Department of Budget and\n5 \nManagement (DBM), the NAIC Council shall determine the organizational structure\n6 \nand staffing pattern of the NAIC Secretariat, in accordance with existing Civil Service\n7 \nCommission laws, rules and regulations.\n8 \nSec. 9. Powers and Functions of the NAIC. - The functions of the NAIC shall\n9 \ninclude, but not limited to, the following:\n10 \na) Develop and integrate the Philippine AI Roadmap, as provided under Sec. 10\n11 \nof this Act;\n12 \nb) Coordinate and directly work with all government agencies, local government\n13 \nunits, and other stakeholders, whether public and private, involved in AI;\n14 \nc) Maintain a National Registry for AI, as provided under Sec. 11 of this Act;\n15 \nd) Create an AI Ethics Review Board, as provided under Sec. 15 of this Act, which\n16 \nwould issue guidelines on AI promotion, sustainable development regulation,\n17 \nsafety, ethical standards and accountability;\n18 \ne) Undertake ethical and sustainability reviews of AI systems in coordination with\n19 \nsectoral regulators and ensure that systems align with social, environmental,\n20 \nand intergenerational goals;\n21 \nf) Implement a risk-based regulatory framework of AI systems, including the\n22 \nclassification of AI systems as high-risk, moderate-risk, or low-risk based on\n23 \ntheir potential impact on safety, rights, and national interest;\n24 \ng) Certify and monitor Al-related risks of all AI applications;\n25 \nh) Support Filipino-developed AI technologies through public-private partnerships\n26 \nand targeted innovation grants;\n27 \ni) Coordinate with the National Privacy Commission, Intellectual Property Office,\n28 \nand relevant agencies to ensure AI systems comply with data privacy,\n29 \nintellectual property, and ethical standards;\n30 \nj) Prioritize AI systems that promote the use of AI in agriculture, health,\n31 \neducation, disaster risk reduction, governance, environmental sustainability,\n32 \nrenewable energy, agriculture, and biodiversity and other sectors;"], "reference": "The context indicates that the NAIC coordinates with the Intellectual Property Office to ensure AI systems comply with data privacy, intellectual property, and ethical standards.", "synthesizer_name": "single_hop_specifc_query_synthesizer"}
{"user_input": "What does Republic Act No 10173 say about AI systems and registration?", "reference_contexts": ["1 \nk) Issue advisory opinions on AI systems that pose unacceptable risks to human\n2 \nrights, public safety, democratic integrity, or environmental sustainability;\n3 \nI) Create an online portal for the public to access registered AI systems, submit\n4 \ncomplaints, and report harms;\n5 \nm) Audit, inspect, or suspend AI systems that are not registered or are found to\n6 \nviolate the provisions of this Act;\n7 \nn) Hear and decide on complaints, and impose administrative penalties, pursuant\n8 \nto the provisions of this Act;\n9 \no) Coordinate with international agencies and organizations that have a similar\n10 \nmandate and expertise in artificial intelligence; and\n11 \np) Perform other functions as may be mandated by law or duly delegated by\n12 \nrelevant authorities, as well as those that may be necessary or expedient for\n13 \nthe performance of its mandate under this Act.\n14 \nSec. 10. Multi-year Philippine AI Roadmap. - The NAIC shall develop and\n15 \nintegrate the multi-year Philippine AI Roadmap that shall guide national and local\n16 \nefforts in harnessing AI. It shall be reviewed at least every three (3) years, or as may\n17 \nbe necessary, to adapt to rapidly evolving global AI and technological trends.\n18 \nThe NAIC shall ensure the progressive realization of the multi-year Philippine\n19 \nAI Roadmap, which should establish clear targets.\n20 \nSec. 11. National Registry of AI Systems. - The. NAIC shall establish, maintain,\n21 \nand regularly update the National Registry of AI Systems. All natural or juridical\n22 \npersons, whether public or private, local or foreign, who develop, deploy, operate,\n23 \nimport, sell, or provide access to AI systems in the Philippines, shall be required to\n24 \nregister such systems with the NAIC.\n25 \nNo AI system shall be imported, sold, deployed, or publicly accessed in the\n26 \nPhilippines without prior registration with the NAIC and full compliance with applicable\n27 \nregulatory and ethical standards.\n28 \nThe NAIC shall ensure that the registry is maintained in accordance with\n29 \nRepublic Act No. 10173, or the Data Privacy Act of 2012, and Republic Act No. 10175,\n30 \nor the Cybercrime Prevention Act of 2012."], "reference": "The NAIC shall establish, maintain, and regularly update the National Registry of AI Systems, and all persons developing, deploying, or selling AI in the Philippines must register their systems with the NAIC. No AI system can be imported, sold, deployed, or accessed publicly without prior registration and full compliance with applicable standards, in accordance with Republic Act No 10173, the Data Privacy Act of 2012, and the Cybercrime Prevention Act of 2012.", "synthesizer_name": "single_hop_specifc_query_synthesizer"}
{"user_input": "NAIC what it do?", "reference_contexts": ["1 \nSec. 12. Contents of AI Registration and Registry. - The registry and the\n2 \napplication for AI registration shall include, but not limited to, the following information\n3 \nfor each AI system:\n4 \na) Name and description of the AI system;\n5 \nb) Intended purpose and sector of deployment;\n6 \nc) Name and address of the developer, deployer, or distributor;\n7 \nd) Nature of the AI foundation model (e.g., machine learning, generative AI, LLM);\n8 \ne) Data sources, intended use, and safeguards for training or development,\n9 \nincluding status or date when the data was last gathered and processed;\n10 \nf) Certification that the AI system has built-in filters or mechanisms to prevent it\n11 \nfrom being used to facilitate any form of crime, fraud, or harm and that the\n12 \ndevelopers are willing to make the necessary adjustments to the program if the\n13 \nNAIC determines that it is unsafe;\n14 \ng) Risk classification, pursuant to this Act and its implementing rules and\n15 \nregulations;\n16 \nh) Compliance with standards for AI safety, transparency, accountability,\n17 \nexplainability, and ethical compliance features, including safeguards against\n18 \ndiscrimination, misuse, harm, or unintended consequences;\n19 \ni) Mechanism for redress or reporting of adverse incidents arising from its use;\n20 \nand\n21 \nj) Any relevant licenses or certifications issued by national or international\n22 \nauthorities.\n23 \nFailure to register or the deliberate concealment of information about an AI system\n24 \nshall be subject to penalties under Sec. 20 of this Act.\n25 \nSec. 13. AI Registration as a Prerequisite. - Registration with the NAIC shall be\n26 \na prerequisite to obtaining any business license or government authorization for the\n27 \ndeployment, importation, distribution, or commercial use of an AI system in the\n28 \ncountry.\n29 \nSec. 14. Market Compiiance. - All AI systems that were already used, imported,\n30 \nor accessible in the Philippines prior to the effectivity of this Act shall be registered\n31 \nwith the NAIC within sixty (60) days from the effectivity of this Act. Failure to comply\n32 \nshall subject the responsible entity to penalties under this Act."], "reference": "The NAIC is involved in registering AI systems, including collecting information like name, purpose, developer details, safety standards, and compliance. Registration is required for deploying or using AI in the country, and existing AI systems must also register within 60 days of the Act's effectivity.", "synthesizer_name": "single_hop_specifc_query_synthesizer"}
{"user_input": "Hwo does the NAICSecretariat's role in implmenting and execueting AI policies relate to the org structure and powers of the NAIC, and how does this impact the implementation and execuion of AI policies?", "reference_contexts": ["<1-hop>\n\n1 \nSec. 8. NAICSecretariat. - The Secretariat shall implement and execute policies\n2 \non AI pursuant to the provisions of this Act. It shall be headed by an Executive\n3 \nDirector, with the rank of an Undersecretary.\n4 \nSubject to the review and approval of the Department of Budget and\n5 \nManagement (DBM), the NAIC Council shall determine the organizational structure\n6 \nand staffing pattern of the NAIC Secretariat, in accordance with existing Civil Service\n7 \nCommission laws, rules and regulations.\n8 \nSec. 9. Powers and Functions of the NAIC. - The functions of the NAIC shall\n9 \ninclude, but not limited to, the following:\n10 \na) Develop and integrate the Philippine AI Roadmap, as provided under Sec. 10\n11 \nof this Act;\n12 \nb) Coordinate and directly work with all government agencies, local government\n13 \nunits, and other stakeholders, whether public and private, involved in AI;\n14 \nc) Maintain a National Registry for AI, as provided under Sec. 11 of this Act;\n15 \nd) Create an AI Ethics Review Board, as provided under Sec. 15 of this Act, which\n16 \nwould issue guidelines on AI promotion, sustainable development regulation,\n17 \nsafety, ethical standards and accountability;\n18 \ne) Undertake ethical and sustainability reviews of AI systems in coordination with\n19 \nsectoral regulators and ensure that systems align with social, environmental,\n20 \nand intergenerational goals;\n21 \nf) Implement a risk-based regulatory framework of AI systems, including the\n22 \nclassification of AI systems as high-risk, moderate-risk, or low-risk based on\n23 \ntheir potential impact on safety, rights, and national interest;\n24 \ng) Certify and monitor Al-related risks of all AI applications;\n25 \nh) Support Filipino-developed AI technologies through public-private partnerships\n26 \nand targeted innovation grants;\n27 \ni) Coordinate with the National Privacy Commission, Intellectual Property Office,\n28 \nand relevant agencies to ensure AI systems comply with data privacy,\n29 \nintellectual property, and ethical standards;\n30 \nj) Prioritize AI systems that promote the use of AI in agriculture, health,\n31 \neducation, disaster risk reduction, governance, environmental sustainability,\n32 \nrenewable energy, agriculture, and biodiversity and other sectors;"], "reference": "The NAICSecretariat is responsible for implementing and executing AI policies as outlined in Sec. 8, headed by an Executive Director with the rank of an Undersecretary. Its organizational structure and staffing pattern are determined by the NAIC Council, subject to review and approval by the Department of Budget and Management, as per Sec. 8. The powers and functions of the NAIC, including developing the AI Roadmap, coordinating with stakeholders, maintaining a registry, creating an ethics review board, and implementing a risk-based regulatory framework, are all carried out by the Secretariat. This organizational setup and the defined powers ensure that the NAICSecretariat effectively manages the implementation and execution of AI policies across sectors, supporting the development of AI standards, ethical guidelines, and regulatory frameworks necessary for responsible AI deployment.", "synthesizer_name": "multi_hop_abstract_query_synthesizer"}
{"user_input": "How does the framework for responsible AI developement address data bias and manipulation to prevent AI hallucinations and ensure ethical standards?", "reference_contexts": ["<1-hop>\n\nAI presents enormous opportunities for the Philippines: improving public services, \nadvancing disaster resilience, modernizing agriculture, and enhancing education and \nhealthcare systems, among others. However, these innovations carry risks. AI systems \nrely on data and models that may be incomplete, biased, or manipulated, reflecting the \nsubjective or commercial choices of developers. These raise concerns such as algorithmic \nbias, discrimination, and AI hallucinations, where systems generate false or misleading \noutputs with confidence. Moreover, the global scientific and policy communities have \nraised alarms regarding the possible rise of Artificial Superintelligence (ASI), hypothetical \nAI systems surpassing human intelligence and potentially beyond human control.3 This \nrisk includes fears that such systems, if improperly secured or regulated, might gain \nunauthorized access to critical infrastructure, including military assets such as nuclear \nweapons, posing existential threats to humanity.\nIn view of these challenges, this bill seeks to strike a careful balance between \nencouraging technological innovation and ensuring that AI systems remain safe, ethical, \ntransparent, and under meaningful human oversight. Given that AI is still in its early \nstages, this bill provides a general framework to encourage its development in a \nresponsible and lawful manner. It envisions a future where AI supports Filipino ingenuity, \naddresses national development challenges, and protects the rights and welfare of every \ncitizen. The State bears the responsibility to ensure that AI will never be used to \nperpetrate crimes, abuse rights, cause harm or unintended consequences, whether \nthrough intent or accident, while supporting Filipino ingenuity and technological progress.\nIn view of the foregoing, the approval of this bill is earnestly sought.\nPIA S: CAY^ANO \\\n3 Center for Security and Emerging Technology. (2024). Securing Critical Infrastructure in the Age of AI. \nGeorgetown University https://cset.georgetown.edu/publication/securing-critical-infrastructure-in-the- \nage-of-ai/"], "reference": "The context highlights that AI systems rely on data and models which may be incomplete, biased, or manipulated, leading to issues such as algorithmic bias, discrimination, and AI hallucinations. The bill aims to create a framework that encourages responsible AI development by ensuring systems remain safe, ethical, transparent, and under human oversight. This approach seeks to mitigate risks associated with data bias and manipulation, thereby supporting ethical standards and preventing unintended harmful consequences.", "synthesizer_name": "multi_hop_abstract_query_synthesizer"}
{"user_input": "How does the legal liabilities for unregistered AI deploymnt relate to the risks of AGI development and the need for regulation?", "reference_contexts": ["<1-hop>\n\n1\n2\n3\n4\n5\n6\n7\n8 \n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20 \n21 \n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\nanalyzing the data and taking actions with some degree of autonomy to \nachieve specific goals.\nb) Artificial General Intelligence (AGI) - refers to AI systems with the \ncapacity to understand, learn, and apply knowledge across a broad \nrange of tasks at a level equal to or surpassing human intelligence.\nc) Artificial Superintelligence (ASI) - refers to hypothetical AI systems that \nsurpass human intelligence in all respects, including creativity, decision­\nmaking, and social intelligence.\nd) AI Foundation Model- refers to a type of large-scale artificial intelligence \nmodel trained on vast quantities of broad data using self-supervised \nlearning or similar techniques, and which can be adapted to a wide range \nof downstream tasks, such as question answering, summarization, \ntranslation, classification, or content generation, with minimal task- \nspecific tuning. Foundation models include, but are not limited to, LLMs, \nmultimodal models, and generative models.\ne) Deployment in AI - refers to the process of integrating and operating a \ntrained AI model into an organizational infrastructure or real-world \nenvironment where it can perform its intended tasks.\nf) Expert Systems - refer to computer programs designed to simulate the \ndecision-making abilities of a human expert in a specific domain.\ng) Futures Thinking - refers to an avenue to strategically explore a range \nof \"possible futures\", with the aim of uncovering unexpected \nopportunities and mitigate potential risks.\nh) Generative Pre-trained Transformers- refer to a type of large language \nmodel based on the transformer architecture that generate human-like \ntext by predicting the next word in a sequence.\ni) Hallucination in AI- refers to the phenomenon wherein an AI system \ngenerates output that is syntactically correct or plausible-sounding but \nfactually incorrect, fabricated, or nonsensical. Hallucinations can occur \nin text, image, audio, or multimodal outputs, and are often the result of \nthe model extrapolating beyond the data it was trained on or failing to", "<2-hop>\n\n1 \ndevelopment priorities. These hubs shall also promote innovation in the sectors of\n2 \ngovernment.\n3 \nSec. 20. Prohibited Acts and Penaities. - Any person, whether natural or\n4 \njuridical, who commits any of the prohibited acts, without prejudice to civil and other\n5 \ncriminal liabilities under existing laws, shall be subject to the following penalties:\n6 \na) Deveiopment or Depioyment of Unregistered AI Systems - any person who\n7 \ndevelops, deploys, distributes, or makes commercially available any AI system\n8 \nwithout prior registration with the NAIC shall be punished with:\n9 \ni) Revocation of business permit or licenses, and blacklisting from\n10 \ngovernment procurement and AI development grants; and\n11 \nii) Impose a fine of Five Hundred Thousand Pesos (Php 500,000) to Five\n12 \nMillion Pesos (Php 5,000,000) or imprisonment of six (6) months to three\n13 \n(3) years, or both, at the discretion of the court;\n14 \nb) Use of AI Systems to Commit, Fadiitate, or Conceai Fraud, Crimes, or Cause\n15 \nHarm-kny person who intentionally uses AI systems to commit fraud, facilitate\n16 \nor conceal crimes, or cause harm to life, liberty, property, or national security\n17 \nshall suffer:\n18 \ni) Impose a fine of Two Million Pesos (Php 2,000,000) to Ten Million Pesos\n19 \n(Php 10,000,000) or imprisonment of six (6) years to twelve (12) years,\n20 \nor both, at the discretion of the court; and\n21 \nii) If the offense results in death, physical injury, or large-scale financial or\n22 \nreputational damage, penalties \nshall be imposed in their maximum\n23 \nperiod.\n24 \nc) Vioiation of Safeguards under this Act, or Ruies and Reguiations Issued by the\n25 \nNAIC or the AI Ethics Review Board- Any person or entity that willfully violates\n26 \nadministrative rules, technical standards, ethical guidelines, or reporting\n27 \nrequirements issued by the NAIC or the AI Ethics Review Board shall be liable\n28 \nfor:\n29 \ni) An administrative fine of One Hundred Thousand Pesos (Php 100,000)\n30 \nto One Million Pesos (Php 1,000,000) per violation;\n31 \nii) Suspension or revocation of registration or certification of the AI system\n32 \ninvolved; and\n12"], "reference": "The context indicates that developing or deploying unregistered AI systems can lead to penalties such as fines, imprisonment, and revocation of permits, highlighting the importance of regulation. Since Artificial General Intelligence (AGI) refers to AI systems with broad, human-level understanding and capabilities, unregulated development of such systems could pose significant risks, including misuse or unintended harm. Therefore, the legal liabilities for unregistered AI deployment are directly related to managing the potential dangers associated with AGI, emphasizing the need for strict regulations and registration to mitigate these risks.", "synthesizer_name": "multi_hop_abstract_query_synthesizer"}
{"user_input": "How does the NAIC's jurisdiction over AI registration requirements relate to its authority to regulate AI development and promote ethical standards?", "reference_contexts": ["<1-hop>\n\n1 \nSec. 6. Jurisdiction of the NAIC - The NAIC shall have the original and exclusive\n2 \njurisdiction over all matters pertaining to AI, including its development, promotion,\n3 \nregistration and regulation. The NAIC shall have quasi-judicial powers to hear and\n4 \ndecide on cases, and impose administrative sanctions provided under Sec. 20 of this\n5 \nAct.\n6 \nThe NAIC shall be responsible for technical support and policy alignment of all\n7 \ngovernment offices, including those under or attached to the DOST and other\n8 \nconcerned agencies involved in AI development. The NAIC shall also have the\n9 \nauthority to impose administrative penalties in case of any violation of this Act.\n10 \nSec. 7. Composition of the NAIC - The NAIC shall be composed of the\n11 \nSecretary of the DOST as Chairman, the Secretary of the Department of Information\n12 \nand Communications Technology (DICT) as Vice Chairperson, and the following as\n13 \nmembers:\n14 \na) Department of Trade and Industry (DTI);\n15 \nb) Department of Education (DepEd);\n16 \nc) Commission on Higher Education (CHED);\n17 \nd) Department of Labor and Employment (DOLE);\n18 \ne) Technical Education and Skills Development Authority (TESDA);\n19 \nf) Department of Justice (DOJ);\n20 \ng) National Privacy Commission (NPC);\n21 \nh) Department of Economy, Planning, and Development (DepDev);\n22 \ni) National Academy of Science and Technology (NAST); and\n23 \nj) One (1) representative each from the following sectors, to be appointed\n24 \nby the President of the Philippines for a term of three (3) years:\n25 \ni) \nThe private technology sector with expertise in AI or data science;\n26 \nii) \nThe civil society sector, with expertise in AI ethics, human rights,\n27 \nor digital governance.\n28 \nEach government agency member may designate a permanent representative\n29 \nto the NAIC, with a rank not lower than an Assistant Secretary or its equivalent, and\n30 \npreferably with proven expertise or relevant background in science and technology,\n31 \ninformation and communications technology, data governance, policy development,\n32 \nor legal and regulatory affairs.", "<2-hop>\n\n1 \nSec. 12. Contents of AI Registration and Registry. - The registry and the\n2 \napplication for AI registration shall include, but not limited to, the following information\n3 \nfor each AI system:\n4 \na) Name and description of the AI system;\n5 \nb) Intended purpose and sector of deployment;\n6 \nc) Name and address of the developer, deployer, or distributor;\n7 \nd) Nature of the AI foundation model (e.g., machine learning, generative AI, LLM);\n8 \ne) Data sources, intended use, and safeguards for training or development,\n9 \nincluding status or date when the data was last gathered and processed;\n10 \nf) Certification that the AI system has built-in filters or mechanisms to prevent it\n11 \nfrom being used to facilitate any form of crime, fraud, or harm and that the\n12 \ndevelopers are willing to make the necessary adjustments to the program if the\n13 \nNAIC determines that it is unsafe;\n14 \ng) Risk classification, pursuant to this Act and its implementing rules and\n15 \nregulations;\n16 \nh) Compliance with standards for AI safety, transparency, accountability,\n17 \nexplainability, and ethical compliance features, including safeguards against\n18 \ndiscrimination, misuse, harm, or unintended consequences;\n19 \ni) Mechanism for redress or reporting of adverse incidents arising from its use;\n20 \nand\n21 \nj) Any relevant licenses or certifications issued by national or international\n22 \nauthorities.\n23 \nFailure to register or the deliberate concealment of information about an AI system\n24 \nshall be subject to penalties under Sec. 20 of this Act.\n25 \nSec. 13. AI Registration as a Prerequisite. - Registration with the NAIC shall be\n26 \na prerequisite to obtaining any business license or government authorization for the\n27 \ndeployment, importation, distribution, or commercial use of an AI system in the\n28 \ncountry.\n29 \nSec. 14. Market Compiiance. - All AI systems that were already used, imported,\n30 \nor accessible in the Philippines prior to the effectivity of this Act shall be registered\n31 \nwith the NAIC within sixty (60) days from the effectivity of this Act. Failure to comply\n32 \nshall subject the responsible entity to penalties under this Act."], "reference": "The NAIC has exclusive jurisdiction over all matters related to AI, including its development, promotion, registration, and regulation, with the authority to impose administrative sanctions and ensure policy alignment among government agencies. Its role in AI registration, as detailed in the registry requirements, is a prerequisite for obtaining business licenses and deploying AI systems, thereby linking its regulatory authority directly to the enforcement of registration standards and ethical compliance features to promote safe and responsible AI development.", "synthesizer_name": "multi_hop_abstract_query_synthesizer"}
{"user_input": "How do registration and licensing requirements for AI systems relate to the framework for responsible AI development and ensuring AI safety and ethics?", "reference_contexts": ["<1-hop>\n\n1 \ndevelopment priorities. These hubs shall also promote innovation in the sectors of\n2 \ngovernment.\n3 \nSec. 20. Prohibited Acts and Penaities. - Any person, whether natural or\n4 \njuridical, who commits any of the prohibited acts, without prejudice to civil and other\n5 \ncriminal liabilities under existing laws, shall be subject to the following penalties:\n6 \na) Deveiopment or Depioyment of Unregistered AI Systems - any person who\n7 \ndevelops, deploys, distributes, or makes commercially available any AI system\n8 \nwithout prior registration with the NAIC shall be punished with:\n9 \ni) Revocation of business permit or licenses, and blacklisting from\n10 \ngovernment procurement and AI development grants; and\n11 \nii) Impose a fine of Five Hundred Thousand Pesos (Php 500,000) to Five\n12 \nMillion Pesos (Php 5,000,000) or imprisonment of six (6) months to three\n13 \n(3) years, or both, at the discretion of the court;\n14 \nb) Use of AI Systems to Commit, Fadiitate, or Conceai Fraud, Crimes, or Cause\n15 \nHarm-kny person who intentionally uses AI systems to commit fraud, facilitate\n16 \nor conceal crimes, or cause harm to life, liberty, property, or national security\n17 \nshall suffer:\n18 \ni) Impose a fine of Two Million Pesos (Php 2,000,000) to Ten Million Pesos\n19 \n(Php 10,000,000) or imprisonment of six (6) years to twelve (12) years,\n20 \nor both, at the discretion of the court; and\n21 \nii) If the offense results in death, physical injury, or large-scale financial or\n22 \nreputational damage, penalties \nshall be imposed in their maximum\n23 \nperiod.\n24 \nc) Vioiation of Safeguards under this Act, or Ruies and Reguiations Issued by the\n25 \nNAIC or the AI Ethics Review Board- Any person or entity that willfully violates\n26 \nadministrative rules, technical standards, ethical guidelines, or reporting\n27 \nrequirements issued by the NAIC or the AI Ethics Review Board shall be liable\n28 \nfor:\n29 \ni) An administrative fine of One Hundred Thousand Pesos (Php 100,000)\n30 \nto One Million Pesos (Php 1,000,000) per violation;\n31 \nii) Suspension or revocation of registration or certification of the AI system\n32 \ninvolved; and\n12", "<2-hop>\n\nAI presents enormous opportunities for the Philippines: improving public services, \nadvancing disaster resilience, modernizing agriculture, and enhancing education and \nhealthcare systems, among others. However, these innovations carry risks. AI systems \nrely on data and models that may be incomplete, biased, or manipulated, reflecting the \nsubjective or commercial choices of developers. These raise concerns such as algorithmic \nbias, discrimination, and AI hallucinations, where systems generate false or misleading \noutputs with confidence. Moreover, the global scientific and policy communities have \nraised alarms regarding the possible rise of Artificial Superintelligence (ASI), hypothetical \nAI systems surpassing human intelligence and potentially beyond human control.3 This \nrisk includes fears that such systems, if improperly secured or regulated, might gain \nunauthorized access to critical infrastructure, including military assets such as nuclear \nweapons, posing existential threats to humanity.\nIn view of these challenges, this bill seeks to strike a careful balance between \nencouraging technological innovation and ensuring that AI systems remain safe, ethical, \ntransparent, and under meaningful human oversight. Given that AI is still in its early \nstages, this bill provides a general framework to encourage its development in a \nresponsible and lawful manner. It envisions a future where AI supports Filipino ingenuity, \naddresses national development challenges, and protects the rights and welfare of every \ncitizen. The State bears the responsibility to ensure that AI will never be used to \nperpetrate crimes, abuse rights, cause harm or unintended consequences, whether \nthrough intent or accident, while supporting Filipino ingenuity and technological progress.\nIn view of the foregoing, the approval of this bill is earnestly sought.\nPIA S: CAY^ANO \\\n3 Center for Security and Emerging Technology. (2024). Securing Critical Infrastructure in the Age of AI. \nGeorgetown University https://cset.georgetown.edu/publication/securing-critical-infrastructure-in-the- \nage-of-ai/"], "reference": "The registration and licensing requirements for AI systems, which include penalties for developing unregistered AI and using AI to commit crimes, are designed to enforce responsible AI development. These regulations aim to ensure that AI systems are properly registered and compliant with safety standards, thereby supporting a framework that promotes ethical use, transparency, and oversight. By establishing legal consequences for violations and emphasizing the importance of responsible deployment, the regulations help mitigate risks such as bias, manipulation, and unintended harm, aligning with the broader goal of developing AI that is safe, ethical, and under meaningful human control.", "synthesizer_name": "multi_hop_abstract_query_synthesizer"}
{"user_input": "How do Sec. 15 and Sec. 17 relate to AI ethics and responsibilitieS in the NAIC framework?", "reference_contexts": ["<1-hop>\n\n1 \nSec. 8. NAICSecretariat. - The Secretariat shall implement and execute policies\n2 \non AI pursuant to the provisions of this Act. It shall be headed by an Executive\n3 \nDirector, with the rank of an Undersecretary.\n4 \nSubject to the review and approval of the Department of Budget and\n5 \nManagement (DBM), the NAIC Council shall determine the organizational structure\n6 \nand staffing pattern of the NAIC Secretariat, in accordance with existing Civil Service\n7 \nCommission laws, rules and regulations.\n8 \nSec. 9. Powers and Functions of the NAIC. - The functions of the NAIC shall\n9 \ninclude, but not limited to, the following:\n10 \na) Develop and integrate the Philippine AI Roadmap, as provided under Sec. 10\n11 \nof this Act;\n12 \nb) Coordinate and directly work with all government agencies, local government\n13 \nunits, and other stakeholders, whether public and private, involved in AI;\n14 \nc) Maintain a National Registry for AI, as provided under Sec. 11 of this Act;\n15 \nd) Create an AI Ethics Review Board, as provided under Sec. 15 of this Act, which\n16 \nwould issue guidelines on AI promotion, sustainable development regulation,\n17 \nsafety, ethical standards and accountability;\n18 \ne) Undertake ethical and sustainability reviews of AI systems in coordination with\n19 \nsectoral regulators and ensure that systems align with social, environmental,\n20 \nand intergenerational goals;\n21 \nf) Implement a risk-based regulatory framework of AI systems, including the\n22 \nclassification of AI systems as high-risk, moderate-risk, or low-risk based on\n23 \ntheir potential impact on safety, rights, and national interest;\n24 \ng) Certify and monitor Al-related risks of all AI applications;\n25 \nh) Support Filipino-developed AI technologies through public-private partnerships\n26 \nand targeted innovation grants;\n27 \ni) Coordinate with the National Privacy Commission, Intellectual Property Office,\n28 \nand relevant agencies to ensure AI systems comply with data privacy,\n29 \nintellectual property, and ethical standards;\n30 \nj) Prioritize AI systems that promote the use of AI in agriculture, health,\n31 \neducation, disaster risk reduction, governance, environmental sustainability,\n32 \nrenewable energy, agriculture, and biodiversity and other sectors;", "<2-hop>\n\n1 \nSec. 15. AI Ethics Review Board - The NAIC shall create an AI Ethics Review\n2 \nBoard which shall issue implementing guidelines, including detailed risk thresholds,\n3 \naudit mechanisms, and sanctions for non-compliance, aligned with the provisions of\n4 \nthis Act. The AI Ethics Review Board shall review risks related to the AI applications\n5 \nand advise on emerging ethical challenges.\n6 \nSec. 16. AI Registration and Risk Ciassification. - The NAIC shall classify AI\n7 \nsystems and applications according to the following risk tiers:\n8 \na) High-risk - AI systems' decisions or operations that significantly affect public\n9 \nsafety, identity, fundamental rights, livelihoods, or access to essential services,\n10 \nand therefore require heightened regulatory oversight. These include, but not\n11 \nlimited to, systems used In education, healthcare, law enforcement, critical\n12 \ninfrastructure, justice, finance, and public administration.\n13 \nAI systems classified as high-risk shall undergo mandatory algorithmic\n14 \nimpact assessments, data privacy reviews, and sustainability screening before\n15 \nbeing certified for use.\n16 \nb) Moderate-risk- AI systems that influence outcomes with a limited or reversible\n17 \neffect on individuals, organizations, or social systems, and do not directly\n18 \ncompromise safety, rights, or critical services. These include systems used in\n19 \nprocess automation, service optimization, internal evaluations, and resource\n20 \nallocation.\n21 \nc) Low-risk - AI systems with minimal impact potential, typically used for non-\n22 \ncritical tasks such as administrative support, personalized content delivery, \nor\n23 \nbasic data visualization, and which do not materially affect rights, \nsafety, or\n24 \npublic interest.\n25 \nSec. 17. Responsibiiities of AI Deveiopers, Depioyers and/or Operators. - All\n26 \ndevelopers, depioyers and/or operators of AI systems shall, include, but not limited to\n27 \nthe following:\n28 \na) Ensure that AI systems are developed and used responsibly, ethically, and\n29 \ntransparently;\n30 \nb) Conduct algorithmic audits for bias, security, and privacy;\n31 \nc) Clearly disclose when users are interacting with AI systems;"], "reference": "Sec. 15 establishes the AI Ethics Review Board, which issues guidelines, risk thresholds, and reviews ethical challenges related to AI applications. Sec. 17 outlines the responsibilities of AI developers, deployers, and operators to ensure responsible, ethical, and transparent AI use, including conducting audits and disclosures. Together, these sections emphasize the importance of ethical standards and responsible practices in AI regulation and development within the NAIC framework.", "synthesizer_name": "multi_hop_specific_query_synthesizer"}
{"user_input": "How do the penalties of Php 300,000 to Php 1,000,000 for failure to disclose AI-generated content relate to the fines of Php 500,000 to Php 5,000,000 for developing unregistered AI systems, and what are the implications for compliance costs in the context of AI regulation enforcement in the Philippines?", "reference_contexts": ["<1-hop>\n\n1 \niii) Mandatory compliance training or ethics audit as a condition for\n2 \nreinstatement or continued operation.\n3 \nd) Failure to Disclose AI-Generated Content or Provide Required Disclaimers- Any\n4 \nperson who knowingly fails to label or disclose Al-generated content,\n5 \nparticularly in sensitive contexts (e.g., political, medical, educational, or legal)\n6 \nshall be penalized with:\n7 \ni) Impose a fine of Three Hundred Thousand Pesos (Php 300,000) to One\n8 \nMillion Pesos (Php 1,000,000) or imprisonment of six (6) months to two\n9 \n(2) years, or both, at the discretion of the court; and\n10 \nii) Platforms or publishers may be held administratively liable for failure to\n11 \nimplement monitoring or compliance protocols;\n12 \ne) Negligent Operation of Harmful or Malfunctioning AI Systems - Any developer\n13 \nor deployer who knowingly allows an AI system to continue operating after it\n14 \nhas exhibited harmful, unlawful, or unpredictable behavior shall be punished\n15 \nwith:\n16 \ni) Impose a fine of Five Hundred Thousand Pesos (Php 500,000) to Three\n17 \nMillion Pesos (Php 3,000,000) or imprisonment of one (1) year to five\n18 \n(5) years, or both, at the discretion of the court; and\n19 \nii) Permanent disqualification from holding any license to develop or\n20 \noperate AI systems in the Philippines, subject to due process.\n21 \nf) Use of AI to Manipulate Public Opinion, Spread Disinformation, or Conduct\n22 \nUnlawful Surveillance - Any person who uses AI to create or disseminate\n23 \ndisinformation, conduct mass opinion manipulation (e.g., through bots,\n24 \ndeepfakes), or carry out surveillance without legal authority shall be punished\n25 \nwith:\n26 \ni) Impose a fine of One Million Pesos (Php 1,000,000) to Five Million Pesos\n27 \n(Php 5,000,000), or imprisonment of three (3) years to ten (10) years,\n28 \nor both, at the discretion of the court; and\n29 \nii) Additional penalties shall apply if such acts are committed during election\n30 \nperiods, public emergencies, or in violation of constitutional rights;\n31 \ng) Misrepresentation of AI-Generated Content as Human-Made - Knowingly\n32 \npassing off Al-generated content (e.g., fake images, news articles.\n13", "<2-hop>\n\n1 \ndevelopment priorities. These hubs shall also promote innovation in the sectors of\n2 \ngovernment.\n3 \nSec. 20. Prohibited Acts and Penaities. - Any person, whether natural or\n4 \njuridical, who commits any of the prohibited acts, without prejudice to civil and other\n5 \ncriminal liabilities under existing laws, shall be subject to the following penalties:\n6 \na) Deveiopment or Depioyment of Unregistered AI Systems - any person who\n7 \ndevelops, deploys, distributes, or makes commercially available any AI system\n8 \nwithout prior registration with the NAIC shall be punished with:\n9 \ni) Revocation of business permit or licenses, and blacklisting from\n10 \ngovernment procurement and AI development grants; and\n11 \nii) Impose a fine of Five Hundred Thousand Pesos (Php 500,000) to Five\n12 \nMillion Pesos (Php 5,000,000) or imprisonment of six (6) months to three\n13 \n(3) years, or both, at the discretion of the court;\n14 \nb) Use of AI Systems to Commit, Fadiitate, or Conceai Fraud, Crimes, or Cause\n15 \nHarm-kny person who intentionally uses AI systems to commit fraud, facilitate\n16 \nor conceal crimes, or cause harm to life, liberty, property, or national security\n17 \nshall suffer:\n18 \ni) Impose a fine of Two Million Pesos (Php 2,000,000) to Ten Million Pesos\n19 \n(Php 10,000,000) or imprisonment of six (6) years to twelve (12) years,\n20 \nor both, at the discretion of the court; and\n21 \nii) If the offense results in death, physical injury, or large-scale financial or\n22 \nreputational damage, penalties \nshall be imposed in their maximum\n23 \nperiod.\n24 \nc) Vioiation of Safeguards under this Act, or Ruies and Reguiations Issued by the\n25 \nNAIC or the AI Ethics Review Board- Any person or entity that willfully violates\n26 \nadministrative rules, technical standards, ethical guidelines, or reporting\n27 \nrequirements issued by the NAIC or the AI Ethics Review Board shall be liable\n28 \nfor:\n29 \ni) An administrative fine of One Hundred Thousand Pesos (Php 100,000)\n30 \nto One Million Pesos (Php 1,000,000) per violation;\n31 \nii) Suspension or revocation of registration or certification of the AI system\n32 \ninvolved; and\n12"], "reference": "The context indicates that failure to disclose AI-generated content can result in penalties ranging from Php 300,000 to Php 1,000,000, emphasizing the importance of transparency in AI deployment. Similarly, developing unregistered AI systems carries penalties of Php 500,000 to Php 5,000,000, along with possible imprisonment, highlighting significant financial and legal risks for non-compliance. These penalties collectively suggest that organizations operating AI systems in the Philippines face substantial compliance costs, including fines and potential legal sanctions, which serve as deterrents against violations and promote adherence to regulatory standards aimed at ensuring ethical and lawful AI use.", "synthesizer_name": "multi_hop_specific_query_synthesizer"}
{"user_input": "How does the DOST contribute to AI regulation and workforce transition according to the NAIC framework?", "reference_contexts": ["<1-hop>\n\n1 \niii) \nProof of employer engagement with displaced workers on alternative\n2 \nemployment pathways.\n3 \nd) Tripartite Oversight and Consuitation - institutionalize a Tripartite AI and Labor\n4 \nTransition Council, composed of representatives from the DOLE, employers'\n5 \norganizations, labor groups, and civil society, to:\n6 \ni) \nReview Al-related employment trends;\n7 \nii) \nRecommend policy safeguards to DOLE and NAIC; and\n8 \niii) \nFacilitate labor-management dialogue in sectors undergoing AI\n9 \ntransformation.\n10 \ne) Skiiis Mapping and Future-Proofing - conduct regular labor market evaluation\n11 \nto identify job categories at risk of automation and promote the following:\n12 \ni) \nProactive skills development aligned with emerging AI demands;\n13 \nii) \nSupport for technical-vocational education, apprenticeships, and digital\n14 \nskills training in collaboration with TESDA, CHED, and DepEd; and\n15 \niii) \nGovernment-led or subsidized upskilling for workers, especially in high-\n16 \nrisk industries.\n17 \nf) Empioyment Guarantee Mechanisms - develop and pilot employment\n18 \nguarantee schemes or public sector work programs for displaced workers due\n19 \nto Al-induced changes in their employment.\n20 \ng) Monitoring and Enforcement- develop a system for reporting and auditing AI-\n21 \ninduced layoffs, with sanctions for non-compliance including administrative\n22 \nfines, revocation of business permits, or disqualification from government\n23 \nincentives.\n24 \nSec. 19. AI and Sustainabie Innovation Hubs. - Regional AI and Sustainable\n25 \nInnovation Hubs shall be established in partnership with the NAIC, DOST research\n26 \ncenters, state universities and colleges (SUCs), and NAIC-accredited private\n27 \ninstitutions.\n28 \nThe NAIC shall also support the creation of specialized training tracks, research\n29 \nlaboratories, public-private innovation hubs, and startup incubation programs to\n30 \nencourage the growth of homegrown AI talent and Filipino-developed AI technologies.\n31 \nCapacity-building efforts shall be inclusive, accessible, and aligned with national\n11", "<2-hop>\n\n1 \nSec. 6. Jurisdiction of the NAIC - The NAIC shall have the original and exclusive\n2 \njurisdiction over all matters pertaining to AI, including its development, promotion,\n3 \nregistration and regulation. The NAIC shall have quasi-judicial powers to hear and\n4 \ndecide on cases, and impose administrative sanctions provided under Sec. 20 of this\n5 \nAct.\n6 \nThe NAIC shall be responsible for technical support and policy alignment of all\n7 \ngovernment offices, including those under or attached to the DOST and other\n8 \nconcerned agencies involved in AI development. The NAIC shall also have the\n9 \nauthority to impose administrative penalties in case of any violation of this Act.\n10 \nSec. 7. Composition of the NAIC - The NAIC shall be composed of the\n11 \nSecretary of the DOST as Chairman, the Secretary of the Department of Information\n12 \nand Communications Technology (DICT) as Vice Chairperson, and the following as\n13 \nmembers:\n14 \na) Department of Trade and Industry (DTI);\n15 \nb) Department of Education (DepEd);\n16 \nc) Commission on Higher Education (CHED);\n17 \nd) Department of Labor and Employment (DOLE);\n18 \ne) Technical Education and Skills Development Authority (TESDA);\n19 \nf) Department of Justice (DOJ);\n20 \ng) National Privacy Commission (NPC);\n21 \nh) Department of Economy, Planning, and Development (DepDev);\n22 \ni) National Academy of Science and Technology (NAST); and\n23 \nj) One (1) representative each from the following sectors, to be appointed\n24 \nby the President of the Philippines for a term of three (3) years:\n25 \ni) \nThe private technology sector with expertise in AI or data science;\n26 \nii) \nThe civil society sector, with expertise in AI ethics, human rights,\n27 \nor digital governance.\n28 \nEach government agency member may designate a permanent representative\n29 \nto the NAIC, with a rank not lower than an Assistant Secretary or its equivalent, and\n30 \npreferably with proven expertise or relevant background in science and technology,\n31 \ninformation and communications technology, data governance, policy development,\n32 \nor legal and regulatory affairs."], "reference": "The DOST contributes to AI regulation and workforce transition by supporting the establishment of AI and Sustainable Innovation Hubs in partnership with the NAIC and other institutions, promoting research, training, and innovation. Additionally, the DOST is involved in skills mapping, future-proofing, and supporting technical-vocational education, apprenticeships, and digital skills training in collaboration with agencies like TESDA, CHED, and DepEd. These efforts aim to develop Filipino AI talent and facilitate workforce adaptation to AI-induced changes, aligning with the NAIC's jurisdiction over AI development, regulation, and policy support.", "synthesizer_name": "multi_hop_specific_query_synthesizer"}
{"user_input": "How does the proposed Artificial Intelligence Regulation Act aim to promote ethical and responsible development of Artificial General Intelligence while ensuring that AI systems are regulated to prevent issues like hallucinations?", "reference_contexts": ["<1-hop>\n\nTWENTIETH CONGRESS OF THE \nREPUBLIC OF THE PHILIPPINES \nFirst Regular Session\n)\nSENATE \nS. No. 2.ci\n25 JUL-2 P4:56\nn;-' :\nIntroduced by Senator PIA S. CAYETANO\nAN ACT\nREGULATING THE DEVELOPMENT AND USE OF ARTIFICIAL INTELLIGENCE \nSYSTEMS IN THE PHILIPPINES, PROMOTING ETHICAL AND RESPONSIBLE \nARTIFICIAL INTELLIGENCE INNOVATION, AND INTEGRATING \nSUSTAINABILITY AND FUTURES THINKING IN NATIONAL POLICY MAKING, \nAND FOR OTHER PURPOSES\nBe it enacted by the Senate and House of Representatives of the Philippines in \nCongress assembled:\n1 \nSection 1. Short Title. - This Act shall be known as the 'Artificial Intelligence\n2 \nRegulation Act (AIRA).\"\n3 \nSec. 2. Declaration of Policy. - It is the policy of the State to recognize that\n4 \nscience and technology are essential for national development and progress. The State\n5 \nshall give priority to research and development, invention, innovation, and their\n6 \nutilization; and to science and technology education, training, and services.1 In this\n7 \nregard, the State shall promote the responsible development and use of Artificial\n8 \nIntelligence (AI) to advance inclusive growth, public service delivery, innovation, and\n9 \nlong-term national resilience. It shall likewise institutionalize futures thinking and\n10 \nsustainability as core principles in education, governance, and innovation. Towards\n11 \nthis end, the State shall advance AI in a manner that is ethical, inclusive, transparent,\n12 \nand accountable.\n13 \nSec. 3. Objectives. - The objectives of this Act are the following:\n1 Article XIV, Section 10 of the Philippine Constitution", "<2-hop>\n\n1\n2\n3\n4\n5\n6\n7\n8 \n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20 \n21 \n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\nanalyzing the data and taking actions with some degree of autonomy to \nachieve specific goals.\nb) Artificial General Intelligence (AGI) - refers to AI systems with the \ncapacity to understand, learn, and apply knowledge across a broad \nrange of tasks at a level equal to or surpassing human intelligence.\nc) Artificial Superintelligence (ASI) - refers to hypothetical AI systems that \nsurpass human intelligence in all respects, including creativity, decision­\nmaking, and social intelligence.\nd) AI Foundation Model- refers to a type of large-scale artificial intelligence \nmodel trained on vast quantities of broad data using self-supervised \nlearning or similar techniques, and which can be adapted to a wide range \nof downstream tasks, such as question answering, summarization, \ntranslation, classification, or content generation, with minimal task- \nspecific tuning. Foundation models include, but are not limited to, LLMs, \nmultimodal models, and generative models.\ne) Deployment in AI - refers to the process of integrating and operating a \ntrained AI model into an organizational infrastructure or real-world \nenvironment where it can perform its intended tasks.\nf) Expert Systems - refer to computer programs designed to simulate the \ndecision-making abilities of a human expert in a specific domain.\ng) Futures Thinking - refers to an avenue to strategically explore a range \nof \"possible futures\", with the aim of uncovering unexpected \nopportunities and mitigate potential risks.\nh) Generative Pre-trained Transformers- refer to a type of large language \nmodel based on the transformer architecture that generate human-like \ntext by predicting the next word in a sequence.\ni) Hallucination in AI- refers to the phenomenon wherein an AI system \ngenerates output that is syntactically correct or plausible-sounding but \nfactually incorrect, fabricated, or nonsensical. Hallucinations can occur \nin text, image, audio, or multimodal outputs, and are often the result of \nthe model extrapolating beyond the data it was trained on or failing to"], "reference": "The Artificial Intelligence Regulation Act (AIRA) aims to promote the responsible development and use of AI, including Artificial General Intelligence (AGI), by establishing policies that emphasize ethics, transparency, and accountability. It recognizes the importance of regulating AI systems to ensure they are developed and deployed responsibly, which includes addressing challenges such as hallucinations—where AI generates incorrect or nonsensical outputs—by promoting standards that mitigate such issues and foster trustworthy AI innovation.", "synthesizer_name": "multi_hop_specific_query_synthesizer"}
{"user_input": "what about artificial superintelligence risks and regulation", "reference_contexts": ["<1-hop>\n\nAI presents enormous opportunities for the Philippines: improving public services, \nadvancing disaster resilience, modernizing agriculture, and enhancing education and \nhealthcare systems, among others. However, these innovations carry risks. AI systems \nrely on data and models that may be incomplete, biased, or manipulated, reflecting the \nsubjective or commercial choices of developers. These raise concerns such as algorithmic \nbias, discrimination, and AI hallucinations, where systems generate false or misleading \noutputs with confidence. Moreover, the global scientific and policy communities have \nraised alarms regarding the possible rise of Artificial Superintelligence (ASI), hypothetical \nAI systems surpassing human intelligence and potentially beyond human control.3 This \nrisk includes fears that such systems, if improperly secured or regulated, might gain \nunauthorized access to critical infrastructure, including military assets such as nuclear \nweapons, posing existential threats to humanity.\nIn view of these challenges, this bill seeks to strike a careful balance between \nencouraging technological innovation and ensuring that AI systems remain safe, ethical, \ntransparent, and under meaningful human oversight. Given that AI is still in its early \nstages, this bill provides a general framework to encourage its development in a \nresponsible and lawful manner. It envisions a future where AI supports Filipino ingenuity, \naddresses national development challenges, and protects the rights and welfare of every \ncitizen. The State bears the responsibility to ensure that AI will never be used to \nperpetrate crimes, abuse rights, cause harm or unintended consequences, whether \nthrough intent or accident, while supporting Filipino ingenuity and technological progress.\nIn view of the foregoing, the approval of this bill is earnestly sought.\nPIA S: CAY^ANO \\\n3 Center for Security and Emerging Technology. (2024). Securing Critical Infrastructure in the Age of AI. \nGeorgetown University https://cset.georgetown.edu/publication/securing-critical-infrastructure-in-the- \nage-of-ai/", "<2-hop>\n\n1\n2\n3\n4\n5\n6\n7\n8 \n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20 \n21 \n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\nanalyzing the data and taking actions with some degree of autonomy to \nachieve specific goals.\nb) Artificial General Intelligence (AGI) - refers to AI systems with the \ncapacity to understand, learn, and apply knowledge across a broad \nrange of tasks at a level equal to or surpassing human intelligence.\nc) Artificial Superintelligence (ASI) - refers to hypothetical AI systems that \nsurpass human intelligence in all respects, including creativity, decision­\nmaking, and social intelligence.\nd) AI Foundation Model- refers to a type of large-scale artificial intelligence \nmodel trained on vast quantities of broad data using self-supervised \nlearning or similar techniques, and which can be adapted to a wide range \nof downstream tasks, such as question answering, summarization, \ntranslation, classification, or content generation, with minimal task- \nspecific tuning. Foundation models include, but are not limited to, LLMs, \nmultimodal models, and generative models.\ne) Deployment in AI - refers to the process of integrating and operating a \ntrained AI model into an organizational infrastructure or real-world \nenvironment where it can perform its intended tasks.\nf) Expert Systems - refer to computer programs designed to simulate the \ndecision-making abilities of a human expert in a specific domain.\ng) Futures Thinking - refers to an avenue to strategically explore a range \nof \"possible futures\", with the aim of uncovering unexpected \nopportunities and mitigate potential risks.\nh) Generative Pre-trained Transformers- refer to a type of large language \nmodel based on the transformer architecture that generate human-like \ntext by predicting the next word in a sequence.\ni) Hallucination in AI- refers to the phenomenon wherein an AI system \ngenerates output that is syntactically correct or plausible-sounding but \nfactually incorrect, fabricated, or nonsensical. Hallucinations can occur \nin text, image, audio, or multimodal outputs, and are often the result of \nthe model extrapolating beyond the data it was trained on or failing to"], "reference": "the context discusses the possible rise of artificial superintelligence (ASI), a hypothetical AI system surpassing human intelligence, which could pose significant risks if not properly secured or regulated. it highlights concerns about ASI gaining unauthorized access to critical infrastructure and the importance of balancing technological progress with safety, ethics, and oversight to prevent harm.", "synthesizer_name": "multi_hop_specific_query_synthesizer"}
